# fiap-tech4 ‚úÖ

## Descri√ß√£o

**fiap-tech4** √© um projeto desenvolvido para a Tech Challenger (Fase 4) que utiliza Machine Learning para prever ind√≠cios de obesidade a partir de caracter√≠sticas sociodemogr√°ficas e comportamentais. A aplica√ß√£o principal √© uma interface Streamlit com p√°ginas para explora√ß√£o, predi√ß√£o, hist√≥rico e gera√ß√£o de PDFs de relat√≥rio.

---

## Sum√°rio

- üìå **Status**: Pronto para entrega
- üöÄ **Tecnologias**: Python, Streamlit, scikit-learn, XGBoost, Joblib
- üìÅ **Dados**: `data/Obesity.csv`, `data/df_model_final.csv`
- üß† **Modelos**: `src/models/*.joblib`

---

## Funcionalidades principais ‚ú®

- Interface web com p√°ginas: **Home**, **Prever**, **Historico**, **Sobre**
- Predi√ß√£o de risco de obesidade com modelos treinados (`RandomForest`, `XGBoost`)
- Gera√ß√£o de relat√≥rios em PDF com suporte a acentua√ß√£o (quando houver fonte TTF dispon√≠vel)
- Pipeline de treinamento e fun√ß√µes de produ√ß√£o (`src/models/train_pipeline.py`, `src/models/production_pipeline.py`)

---

## Estrutura do reposit√≥rio üîß

- `src/` ‚Äì c√≥digo-fonte da aplica√ß√£o
  - `app.py` ‚Äì ponto de entrada do Streamlit
  - `1_dash.py` ‚Äì dashboard auxiliar
  - `models/` ‚Äì pipelines de treino e modelos serializados (`.joblib`)
  - `pages/` ‚Äì telas do Streamlit (Home, Prever, Hist√≥rico, Sobre)
  - `utils/` ‚Äì utilit√°rios (conex√£o, plots, scripts auxiliares)
- `data/` ‚Äì datasets usados no projeto (`Obesity.csv`, `df_model_final.csv`)
- `README.md` ‚Äì documenta√ß√£o (este arquivo)
- `pyproject.toml` / `requirements.txt` ‚Äì depend√™ncias

---

## Pr√©-requisitos ‚úÖ

- Python 3.11+ (o projeto declara compatibilidade com >=3.11)
- Recomenda-se criar um ambiente virtual (venv/conda/poetry)

---

## Instala√ß√£o e execu√ß√£o üöÄ

### Com pip

1. Criar e ativar um ambiente virtual
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Linux / macOS
   .\.venv\Scripts\Activate  # Windows (PowerShell/CMD)
   ```
2. Instalar depend√™ncias
   ```bash
   pip install -r requirements.txt
   ```
3. Rodar a aplica√ß√£o Streamlit
   ```bash
   streamlit run src/app.py
   ```

### Com Poetry

1. Instalar depend√™ncias
   ```bash
   poetry install
   ```
2. Executar app (script configurado em `pyproject.toml`)
   ```bash
   poetry run app
   ```

> Dica: existe o utilit√°rio `src/utils/run_streamlit.py` que programa a execu√ß√£o via API do Streamlit (√∫til para deploys e testes automatizados).

---

## Uso da API de produ√ß√£o (exemplo) üß©

Voc√™ pode carregar um modelo e rodar uma previs√£o programaticamente usando `src/models/production_pipeline.py`:

```python
from src.models.production_pipeline import load_model, predict_from_input

model = load_model('src/models/random_forest_final.joblib')

input_example = {
    'Gender': 'Male',
    'Age': 25,
    'Height': 1.75,
    'Weight': 70,
    'family_history': 'yes',
    'FAVC': 'no',
    'FCVC': 2,
    'NCP': 3,
    'CAEC': 'Sometimes',
    'SMOKE': 'no',
    'CH2O': 2,
    'SCC': 'no',
    'FAF': 1,
    'TUE': 2,
    'CALC': 'no',
    'MTRANS': 'Public_Transportation'
}

resultado = predict_from_input(model, input_example)
print(resultado)
```

---

## Treinamento / Reprodutibilidade üîÅ

O pipeline de treino est√° em `src/models/train_pipeline.py`. Para reproduzir um treino simples:

1. Carregue os dados em `data/` e prepare `X`/`y` conforme utilizado no projeto.
2. Importe `train_model` e passe o estimador desejado (ex.: `RandomForestClassifier`).

Exemplo m√≠nimo:

```python
from src.models.train_pipeline import train_model
from sklearn.ensemble import RandomForestClassifier

clf, metrics, splits = train_model(X, y, RandomForestClassifier(n_estimators=100), save_model=True, model_name='random_forest_final')
```

---

## Valida√ß√£o e m√©tricas üìä

- M√©tricas computadas no pipeline: **accuracy**, **f1_score**, **recall**, **precision**, **confusion_matrix** e **classification_report**.
- Testes manuais recomendados: executar a p√°gina `Prever`, gerar PDFs e comparar previs√µes com subconjunto conhecido.

---

## Dados üóÑÔ∏è

Principais arquivos de dados:

- `data/Obesity.csv` ‚Äî dataset original com atributos demogr√°ficos e comportamentais
- `data/df_model_final.csv` ‚Äî vers√£o processada utilizada para treino/avalia√ß√£o

> Aten√ß√£o: dados podem conter colunas categ√≥ricas codificadas (veja `src/models/production_pipeline.py` para mapeamentos usados em produ√ß√£o).

---

## Boas pr√°ticas para entrega final ‚úÖ

- Verifique se `requirements.txt` ou `pyproject.toml` cont√©m todas as depend√™ncias.
- Confirme que `src/models/*.joblib` est√£o atualizados e funcionais.
- Teste a gera√ß√£o de PDF em uma m√°quina Windows (verifique fonte TTF para acentua√ß√£o).
- Atualize este README com quaisquer instru√ß√µes espec√≠ficas de deploy se for necess√°rio (Docker/Kubernetes).

---

## Contribui√ß√£o e contato ü§ù

- Autor: **grupo-tech-data-analytics-fiap** ‚Äî ``
- Para d√∫vidas sobre o projeto, execu√ß√£o ou entrega final, envie um e-mail com o assunto: **[fiap-tech4] D√∫vida / Entrega**.

---

## Licen√ßa

Licen√ßa n√£o especificada. Para uso, distribui√ß√£o ou publica√ß√£o consulte o autor respons√°vel pelo reposit√≥rio.

---

## Checklist de entrega final üßæ

- [ ] C√≥digo funcional (rodar `streamlit run src/app.py`)
- [ ] Modelos (`.joblib`) inclu√≠dos em `src/models/`
- [ ] Dados m√≠nimos de exemplo no diret√≥rio `data/`
- [ ] Este `README.md` atualizado e claro para avaliadores


---

**Obrigado!** ‚ú®